# Cài đặt thư viện
!pip install tensorflow opencv-python numpy scikit-learn

# Import thư viện
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import os
import json
from google.colab import drive

# Mount Google Drive
try:
    drive.mount('/content/drive', timeout_ms=60000)
    print("Google Drive đã được mount thành công")
except Exception as e:
    print(f"Lỗi khi mount Google Drive: {str(e)}")
    raise SystemExit("Vui lòng kiểm tra kết nối mạng hoặc tài khoản Google và thử lại")

# Đường dẫn
data_dir = '/content/drive/MyDrive/dataset'
model_path = '/content/drive/MyDrive/AI_Model/oppd_model.h5'
labels_path = '/content/drive/MyDrive/AI_Model/labels.json'

# Tạo ImageDataGenerator cho tăng cường dữ liệu
datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2
)

# Tải dữ liệu từ các thư mục
try:
    train_generator = datagen.flow_from_directory(
        data_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='sparse',
        subset='training'
    )
    validation_generator = datagen.flow_from_directory(
        data_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='sparse',
        subset='validation'
    )
except Exception as e:
    print(f"Lỗi khi tải dữ liệu: {str(e)}")
    raise SystemExit("Kiểm tra thư mục dataset và cấu trúc dữ liệu")

# Kiểm tra số lượng ảnh
if train_generator.samples == 0:
    raise ValueError("Không tìm thấy ảnh nào trong tập huấn luyện. Kiểm tra lại dataset.")
if validation_generator.samples == 0:
    raise ValueError("Không tìm thấy ảnh nào trong tập kiểm tra. Kiểm tra lại dataset.")

print(f"Số ảnh huấn luyện: {train_generator.samples}")
print(f"Số ảnh kiểm tra: {validation_generator.samples}")

# Tạo nhãn chi tiết (species_stage)
labels = {}
for class_name, idx in train_generator.class_indices.items():
    # class_name có dạng "APESV/stage_1"
    species, stage = class_name.split('/')
    labels[idx] = {"species": species, "stage": stage}

print(f"Các lớp: {labels}")

# Hàm xây dựng mô hình CNN
def build_model(num_classes, input_shape=(224, 224, 3)):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])

    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Huấn luyện mô hình
print("Bắt đầu huấn luyện mô hình...")
num_classes = len(train_generator.class_indices)
model = build_model(num_classes)
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=3,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size
)

# Lưu mô hình
model.save(model_path)
print(f"Mô hình đã được lưu vào {model_path}")

# Đánh giá mô hình
test_loss, test_accuracy = model.evaluate(validation_generator)
print(f"Độ chính xác trên tập kiểm tra: {test_accuracy:.4f}")

# Lưu nhãn
if not labels:
    raise ValueError("Danh sách nhãn rỗng. Kiểm tra lại dataset.")
print(f"Danh sách nhãn trước khi lưu: {labels}")
with open(labels_path, 'w') as f:
    json.dump(labels, f)
print(f"Nhãn đã được lưu vào {labels_path}")